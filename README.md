# Окно знаний YSL
Команда YSL MISIS
## Краткое описание проекта
Нам хотелось сделать user-experience как можно более удачным, поэтому при разработке интерфейса сделали его максимально интуитивным. Страница разделена две секции: настраивание ассистента и демонстрация. 

В настройках можно загружать свою базу знаний в различных форматах, изменять шрифт и цвета интерфейса, выбирать модель для обработки данных и chunk-size.

Демонстрация позволяет пользователю сразу видеть результат своих изменений и проводить тесты ассистента. Окно оформлено с опорой на классическую стилистику чат-бота, поэтому достаточно отправить свой запрос в отведенном окошке и подождать ответное сообщение. 

Также есть возможность экспорта ассистента в виде HTML страницы, что даёт возможность для удобного внедрения продукта в сторонние ресурсы.

Модели эмбеддингов и поиска (например, Hugging Face и FAISS) обеспечивают базу данных для хранения и поиска информации.
LLaMA и Ollama обеспечивают обработку запросов и генерацию ответов на основе найденных данных.
Конфигурация модели хранится в JSON-файле, что позволяет гибко управлять параметрами (размер чанков, выбор модели эмбеддингов и т. д.).
Все эти компоненты интегрированы в единое решение, где пользователи могут создавать модели, добавлять данные и задавать вопросы, а система будет искать информацию и генерировать ответы с учетом контекста.

Уникальность нашего продукта заключается в возможности гибкого изменения бизнес-логики со стороны как пользователя, так и разработчиков. При желании можно добавить между моделью и сервером брокер-сообщения, что позволит ещё сильнее ускорить обработку данных.


# Руководство по установке и запуску проекта

Этот проект состоит из нескольких частей: серверного приложения на Go, Python сервера для машинного обучения, базы данных PostgreSQL, а также моделей для взаимодействия с Ollama.

## 1. Требования

Перед тем как начать, убедитесь, что у вас установлены следующие инструменты:

- Go — для сборки и запуска серверного приложения на Go (Версия Go: 1.23+).
- Python 3.x — для запуска серверной части машинного обучения на Python.
- Docker и Docker Compose — для управления контейнерами, включая базу данных и другие сервисы.
- Ollama — для работы с моделями машинного обучения (модели Llama3.2).

## 2. Установка зависимостей

### 2.1 Установка Go зависимостей

Перейдите в директорию backend и установите все Go-зависимости:

```bash
cd backend
go mod tidy
```

###2.2 Установка Python зависимостей
Перейдите в директорию ml и установите все Python-зависимости:

```bash
cd ml
pip install -r requirements.txt
```
###2.3 Установка Docker
Если у вас ещё не установлен Docker и Docker Compose, следуйте инструкциям на официальных страницах:

Установка Docker
Установка Docker Compose
##3. Скачивание моделей для Ollama
Для работы с машинным обучением в проекте используются модели llama3.2:1b-instruct-fp16 и llama3.2:3b-instruct-fp16. Чтобы скачать эти модели, установите Ollama.

###3.1 Установка Ollama
Перейдите на официальную страницу Ollama и следуйте инструкциям по установке.

###3.2 Скачивание моделей
После установки Ollama, загрузите модели с помощью следующих команд (это делайте в командной строке)

```bash
ollama pull llama3.2:1b-instruct-fp16
ollama pull llama3.2:3b-instruct-fp16
```
##4. Запуск приложения
###4.1 Запуск Go приложения
Перейдите в директорию с Go-приложением:
```bash
cd backend/
```
Cкомпилируйте и запустите серверное приложение:
```bash
go run cmd/app/main.go
```
Это приложение подключится к базе данных, выполнит миграции и запустит сервер на порту 8090.

###4.2 Запуск Python сервера (ml)
Перейдите в директорию ml и запустите сервер:
```bash 
cd ml
python server.py
```
Этот сервер будет использовать модели Llama для выполнения задач, связанных с машинным обучением.

###4.3 Запуск Docker Compose
Перейдите в директорию, где находится файл docker-compose.yaml для настройки базы данных:
```bash
cd backend/internal/pkg/db
```
Запустите Docker Compose, чтобы создать и запустить контейнеры:

```bash
docker-compose up
```
Это создаст контейнер для базы данных PostgreSQL, который будет использоваться вашим Go приложением. База данных будет инициализирована с данными из migration.sql.

###4.4 Ожидание готовности базы данных
Go приложение будет ожидать подключения к базе данных перед выполнением миграций. Убедитесь, что база данных PostgreSQL готова принимать соединения. Если вы столкнулись с проблемами подключения, попробуйте проверить логи контейнера с базой данных.

##5. Завершение
После выполнения всех шагов, ваш проект должен быть настроен и готов к использованию. Приложение будет работать на порту 8090 и принимать запросы, обрабатывая данные с использованием машинного обучения и базы данных PostgreSQL.

##6. Примечания
Модели машинного обучения: Все модели, используемые в проекте, загружаются через Ollama. Убедитесь, что у вас есть достаточно места на диске для их хранения.
Порты: Убедитесь, что порты, которые использует приложение (например, 8090 для сервера и 5432 для базы данных), не заняты другими процессами на вашем компьютере.
Системные требования: Для эффективной работы моделей Llama3.2 требуется наличие подходящих аппаратных ресурсов, таких как GPU или достаточно мощный CPU.
